{
    "collab_server" : "",
    "contents" : "# server.R file\nsource(\"listAgencies.R\")\n\n######### BUILDING THE MODEL (run once)\n# Import statements\nlibrary(caret)\n\n# Read data into app\nrecent_data <- read.csv(\"data/recent-requests-data-for-model.csv\", stringsAsFactors = TRUE)\n# Create target variable for successful or not\nrecent_data$successful_bool <- ifelse(recent_data$status == \"done\", 1, 0)\nrecent_data$ref_fees <- as.numeric(recent_data$ref_fees)\nrecent_data$hyperlink <- as.numeric(recent_data$hyperlink)\nrecent_data$specificity <- as.numeric(recent_data$specificity)\nrecent_data$ref_foia <- as.numeric(recent_data$ref_foia)\nrecent_data$email_address <- as.numeric(recent_data$email_address)\nrecent_data$word_count <- as.numeric(recent_data$word_count)\nrecent_data$high_success_rate_agency <- as.numeric(recent_data$high_success_rate_agency)\n\n# Break into training and testing sets with 70% in train. We also use seed to make sure the same partitions are made\n# each time the code in run.\nset.seed(3033)\nintrain <- createDataPartition(y = recent_data$successful_bool, p= 0.7, list = FALSE)\ntraining <- recent_data[intrain,]\ntesting <- recent_data[-intrain,]\n\n# Train model\ntrctrl <- trainControl(method = \"repeatedcv\", number = 10, repeats = 3)\nset.seed(3333)\nknn_fit <- train(successful_bool ~ ref_fees + hyperlink + specificity + ref_foia + avg_sen_len + \n                   email_address + word_count + high_success_rate_agency, \n                 data = training, method = \"knn\",\n                 trControl=trctrl,\n                 preProcess = c(\"center\", \"scale\"),\n                 tuneLength = 10)\n\n########## Text analytics of user input\nlibrary(stringr)\nlibrary(NLP, warn = FALSE)\nlibrary(openNLP, warn = FALSE)\n\nInputTextMining <- function(request_text){\n  # Remove non ascii characters\n  Encoding(request_text) <- \"latin1\"\n  request_text <- iconv(request_text, \"latin1\", \"ASCII\", sub=\"\")\n  \n  # Lowercase text\n  request_text <- tolower(request_text)\n  # Get word count of lowercased text\n  word_count <- sapply(gregexpr(\"[[:alpha:]]+\", request_text), function(x) sum(x > 0))\n  word_count <- as.numeric(word_count)\n  # Sentence count = number of periods, question marks or exclamation points\n  sen_count <- str_count(request_text, \"\\\\.\") + str_count(request_text,\"\\\\?\") + str_count(request_text,\"!\")\n  # If the sentence count is 0, then count the whole phrase as a sentence\n  if (sen_count != 0) {\n    avg_sen_len <- word_count / sen_count\n    avg_sen_len <- as.numeric(avg_sen_len)\n  }\n  else{\n    avg_sen_len <- word_count\n  }\n  \n  # 1 or 0 for boolean presence\n  match_fees <- c(\"fees\")\n  ref_fees <- ifelse(grepl(paste(match_fees,collapse=\"|\"), request_text),1,0)\n  ref_fees <- as.numeric(ref_fees)\n  match_foia <- c(\"foia\",\"freedom of information\")\n  ref_foia <- ifelse(grepl(paste(match_foia,collapse=\"|\"), request_text),1,0)\n  ref_foia <- as.numeric(ref_foia)\n  match_hyperlink <- c(\"((https?):((//)|(\\\\\\\\))+[\\\\w\\\\d:#@%/;$()~_?\\\\+-=\\\\\\\\.&]*)\",\"(www.(?:[a-z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-f][0-9a-f]))+)\")\n  hyperlink <- ifelse(grepl(paste(match_hyperlink,collapse=\"|\"), request_text),1,0)\n  hyperlink <- as.numeric(hyperlink)\n  match_email <- c(\"([\\\\w\\\\-\\\\.]+@(\\\\w[\\\\w\\\\-]+\\\\.)+[\\\\w\\\\-]+)\")\n  email_address <- ifelse(grepl(paste(match_email,collapse=\"|\"), request_text),1,0)\n  email_address <- as.numeric(email_address)\n  \n  tagPOS <-  function(x, ...) {\n    s <- as.String(x)\n    word_token_annotator <- Maxent_Word_Token_Annotator()\n    a2 <- NLP::Annotation(1L, \"sentence\", 1L, nchar(s))\n    a2 <- NLP::annotate(s, word_token_annotator, a2)\n    a3 <- NLP::annotate(s, Maxent_POS_Tag_Annotator(), a2)\n    a3w <- a3[a3$type == \"word\"]\n    POStags <- unlist(lapply(a3w$features, `[[`, \"POS\"))\n    return (POStags)\n  }\n  \n  # Function to return specificity score\n  SpecificityScore <- function(pos_tags){\n    counter <- 0\n    last_tag <- \"\" \n    for (tag in pos_tags){\n      if (tag=='NN' && last_tag!='NN'){\n        counter <- counter + 1 \n      }\n      if (tag!=\".\" | tag!=\",\" | tag!=\"?\" | tag!=\"!\"){\n        last_tag <- tag \n      }\n    }\n    return (counter)\n  }\n  \n  pos_tags <-  tagPOS(request_text)\n  specificity <- SpecificityScore(pos_tags)\n  specificity <- as.numeric(specificity)\n  \n  return (c(word_count, avg_sen_len, ref_fees, ref_foia, hyperlink, email_address, specificity))\n}\n\n\n\n\nshinyServer(function(input, output) {\n  \n  observeEvent(\n    eventExpr = input[[\"submit_loc\"]],\n    handlerExpr = {\n      \n      high_success_rate_agency <- ifelse(input$agency == \"Agency not listed\", 0, 1)\n      \n      output$textResult <- renderText({ \n        \n        validate(\n          need(input$request_text != \"\", \"Please fill out the fields to the left.\")\n        )\n        \n        textmined <- InputTextMining(input$request_text)\n\n        # If word count is smaller than 14, ask for longer request text.\n        if (textmined[1] < 14){\n          paste(\"ERROR: 90% of successful requests are longer than 10 words, please expand your request.\")\n        }\n        else {\n          user_instance <- data.frame(\"ref_fees\" = as.numeric(textmined[3]), \n                                      \"hyperlink\" = as.numeric(textmined[5]),\n                                      \"specificity\" = as.numeric(textmined[7]),\n                                      \"ref_foia\" = as.numeric(textmined[4]),\n                                      \"avg_sen_len\" = as.numeric(textmined[2]),\n                                      \"email_address\" = as.numeric(textmined[6]),\n                                      \"word_count\" = as.integer(textmined[1]),\n                                      \"high_success_rate_agency\" = as.numeric(high_success_rate_agency))\n          \n          user_pred <- predict(knn_fit, newdata=user_instance)\n          \n          formated_prediction <- round(user_pred * 100, 0)\n          \n          paste(\"Your FOIA request has a\", formated_prediction, \"% chance of success\")\n        }\n        \n      })\n      \n      output$cta <- renderUI({\n        ctaText <- '</br> \n        This prediction was made using a K nearest neighbors classification algorithm with a test classification accuracy\n        rate of 80%. \n        </br> This model is based off FOIA request data from the Muckrock API.\n        <a href = \"https://data.world/rdowns26/foia-analysis\"><b>View the data on data.world.</b></a>\n        </br>\n        Have ideas on how to improve our model? <a href = \"#\">Contribute to our open source project.</a>\n        </br>\n        <h4>What makes a FOIA more likely to be successful?</h4>\n        We found the following from our exploratory analysis:\n        <ul>\n          <li>finding number 1</li>\n          <li>finding number 2</li>\n          <li>finding number 3</li>\n        </ul>\n        '\n        HTML(paste(ctaText))\n      })\n      \n    }\n  )\n\n})\n",
    "created" : 1494017471958.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2338713238",
    "id" : "9EAD6BCB",
    "lastKnownWriteTime" : 1494563063,
    "last_content_update" : 1494563063579,
    "path" : "~/Documents/Work/data.world/FOIA/FOIA_Shiny_App/server.R",
    "project_path" : "server.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}